import "../preamble.prag"
import "../memory.prag"
import "../math.prag"
import "../random.prag"

let relu = fun(x: f32) => f32 {
    if (x > 0.0) {
        return x;
    } else {
        return 0.0;
    }
}

let layer = struct(
    activations: column_vec;
    bias: column_vec;
    weights: matrix;
    
    delta_bias: column_vec;
    grad_bias: column_vec;
    grad_weights: matrix;
    delta_weights: matrix;
    last_error: f32;
);


let network = struct(
    layers: layer[];
);

let matrix = struct (
    row_count: i32;
    column_count: i32;
    elements: f32[];  
);

let column_vec = struct (
    elements: f32[];  
);

let dataset = struct (
    input: column_vec*;
    output: column_vec*;
    count: i32;
);


let at = fun(@m: matrix; row_idx: i32; column_idx: i32) => f32{
    assert(row_idx*column_idx < m.elements.length);
    assert(row_idx < m.row_count);
    assert(column_idx < m.column_count);
    return m.elements[row_idx * column_count + column_idx];
}

let dot = fun(v: column_vec; m: matrix; dest: column_vec) => void {
    for (var i = 0; i < dest.elements.length; ++i) {
        var temp = 0.0;
        for (var j = 0; j < v.elements.length; ++j) {
            var f0 = at(m, j, i);
            var f1 =  v.elements[j];
            temp += f0 * f1;
        }
        dest.elements[i] = temp;
    }
}

let create_matrix = fun(row_count: i32; column_count: i32; arena: memory_arena* = &temp_memory_arena) => matrix {
    var result = matrix {};
    result.row_count = row_count;
    result.column_count = column_count;
    result.elements.length = row_count * column_count;
    var size = size_of(f32) * result.elements.length@mm;
    result.elements.data = push(arena, size)@f32*;
    return result;
}

let init_weight_matrix = fun(@m: matrix; half_range: f32 = 0.1) => void {
    for (var idx = 0; idx < elements.length; ++idx) {
        elements[idx] = Random::rand_f32(-half_range, +half_range);
    }    
}

let create_matrix = fun(row_count: i32; column_count: i32; values: f32[]; arena: memory_arena* = &temp_memory_arena) => matrix {
    var result = create_matrix(row_count, column_count, arena);
    var size = size_of(f32) * result.elements.length@mm;
    memcpy(result.elements.data@ptr, values.data@ptr, size);
    return result;
}


let create_column_vec = fun(length: i32; arena: memory_arena* = &temp_memory_arena) => column_vec {
    var result = column_vec {};
    result.elements.length = length;
    var size = size_of(f32) * length@mm;
    result.elements.data = push(arena, size)@f32*;
    return result;
}

let create_column_vec = fun(values: f32[]; arena: memory_arena* = &temp_memory_arena) => column_vec{
    var result = create_column_vec(values.length, arena);
    var size = size_of(f32) * values.length@mm;
    memcpy(result.elements.data@ptr, values.data@ptr, size);
    return result;
}

let debug_print = fun(name: string; v: column_vec) => void {
    print("[ ");
    for (var idx = 0; idx < v.elements.length; ++idx) {
        var value = v.elements[idx];
        print(value);
        if (idx != v.elements.length - 1) {
            print(", ");
        }
    }
    print(" ]\n");
}


let debug_print = fun(name: string; m: matrix) => void {
    print("[\n");
    for (var row_idx = 0; row_idx < m.row_count; ++row_idx) {
        print("  [ ");
        var row = m.elements[row_idx*m.column_count:(row_idx*m.column_count + m.column_count)];
        for (var idx = 0; idx < row.length; ++idx) {
            var value = row[idx];
            print(value);
            if (idx != row.length - 1) {
			    print(", ");
		    }
        }
        print(" ]");
        if (row_idx < m.row_count - 1) {
            print(",\n");
        } else {
            print("\n");
        }
    }
    print("]\n");
}

let approx_equal = fun(a: f32; b: f32; EPSILON:f32 = 0.000001) => bool {
    return Math::abs(a - b) < EPSILON;
}
let test_matrix = fun() => void {
    var mv = [0.37159574, 0.86752783, 0.76533697, 0.03678563, 0.03157477, 0.97958057];
    var m0 = create_matrix(
        3, 2, 
        mv[:]
    );
    debug_print("m0", m0);
    
    var vv = [0.49637618, 0.71788844, 0.89755807];
    var v0 = create_column_vec(vv[:]);
    debug_print("v0", v0.elements);
    var r = create_column_vec(2);
    dot(v0, m0, r);
    debug_print("r", r.elements);
    assert(approx_equal(r.elements[0], 0.76221803) && approx_equal(r.elements[1], 1.33625858));
}

let create_layer = fun(count: i32; output_count: i32; arena: memory_arena* = &temp_memory_arena) => layer {
    var result = layer {};
    result.activations = create_column_vec(count, arena);
    for (var idx = 0; idx < result.bias.elements.length; ++idx) {
        result.activations.elements[idx] = 0.0;
    }
    
    if (output_count > 0) {
        var weight_size = @mm count * @mm output_count * size_of(f32);
        result.weights = create_matrix(count, output_count, arena);
        init_weight_matrix(result.weights);
               
        result.grad_weights = create_matrix(count, output_count, arena);
        zero(result.grad_weights);
        result.delta_weights = create_matrix(count, output_count, arena);
        init_weight_matrix(result.delta_weights);
        
        result.bias = create_column_vec(output_count, arena);
        
        result.grad_bias = create_column_vec(output_count, arena);
        zero(result.grad_bias);
        
        result.delta_bias = create_column_vec(output_count, arena);
        for (var idx = 0; idx < result.bias.elements.length; ++idx) {
            result.bias.elements[idx] = 0.0;
            result.delta_bias.elements[idx] = Random::rand_f32(-0.01, 0.01);
        }
        
    }
    return result;
}

let zero = fun(m: matrix) => void {
    for (var i = 0; i < m.elements.length; ++i) {
        m.elements[i] = 0.0;
    }
}

let zero = fun(v: column_vec) => void {
    for (var i = 0; i < v.elements.length; ++i) {
        v.elements[i] = 0.0;
    }
}

let copy = fun (from: column_vec; to: column_vec) => void {
    assert(from.elements.length == to.elements.length);
    var size = @mm from.elements.length * size_of(f32);
    memcpy(to.elements.data@ptr, from.elements.data@ptr, size);
}

let copy = fun(from: matrix; to: matrix) => void {
    assert(from.elements.length == to.elements.length);
    var size = @mm from.elements.length * size_of(f32);
    memcpy(to.elements.data@ptr, from.elements.data@ptr, size);
}


let create_network = fun(input_count: i32; hidden_count: i32; output_count: i32; arena: memory_arena* = &temp_memory_arena) => network {
    var result = network {};
    let layer_count = 3;
    var size = @mm layer_count * size_of(layer);
    result.layers.data = @layer* push(arena, size);
    result.layers.length = layer_count;
    
    result.layers[0] = create_layer(input_count, hidden_count);
    result.layers[1] = create_layer(hidden_count, output_count);
    result.layers[2] = create_layer(output_count, 0);
    
    return result;
}


let forward = fun(@layer: layer; dest: column_vec) => void {
    dot(activations, weights, dest);
    for (var idx = 0; idx < dest.elements.length; ++idx) {
        dest.elements[idx] += bias.elements[idx];
    }
    for (var idx = 0; idx < dest.elements.length; ++idx) {
        var a = dest.elements[idx];
        dest.elements[idx] = relu(a);
    }
}

let forward = fun(@network: network; input: column_vec) => void {
    var input_activations = layers[0].activations;
    assert(input_activations.elements.length == input.elements.length);
    copy(input, input_activations);
    for (var layer_idx = 0; layer_idx < layers.length - 1; ++layer_idx) {
        forward(layers[layer_idx], layers[layer_idx + 1].activations);
    }
}


let xor_dataset = fun(arena: memory_arena* = &temp_memory_arena) => dataset {
    var result = dataset {};
    var inputs = [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0];
    var outputs = [0.0, 0.0, 1.0, 1.0];
    
    result.input = @column_vec* push(arena, size_of(column_vec) * 4);
    
    var size_vec = size_of(column_vec);
    var ptr0 = result.input + 0;
    var ptr1 = result.input + 1;
    var ptr2 = result.input + 2;
    var ptr3 = result.input + 3;
    
    *(result.input + 0) = create_column_vec(inputs[0:2], arena); 
    *(result.input + 1) = create_column_vec(inputs[2:4], arena);
    *(result.input + 2) = create_column_vec(inputs[4:6], arena);
    *(result.input + 3) = create_column_vec(inputs[6:8], arena);
    
    result.output = @column_vec* push(arena, size_of(column_vec) * 4);
    *(result.output + 0) = create_column_vec(outputs[0:1], arena);
    *(result.output + 1) = create_column_vec(outputs[1:2], arena);
    *(result.output + 2) = create_column_vec(outputs[2:3], arena);
    *(result.output + 3) = create_column_vec(outputs[3:4], arena);
    
    result.count = 4;
    return result;     
}


var execute = fun(network: network; dataset: dataset; verbose: bool = false) => f32 {
    var result = 0.0;
    for (var idx = 0; idx < dataset.count; ++idx) {
        var ptr_inp = dataset.input + idx;
        var ptr_out = dataset.output + idx;
        var inp = *ptr_inp;
        var out = *ptr_out;
        
        forward(network, inp);
        var out_pred = network.layers[network.layers.length - 1].activations;
        if (verbose) {
            debug_print("inp", inp);
            debug_print("out", out);
            debug_print("pred", out_pred);
            print("\n");
        }
        for (var i = 0; i < out.elements.length; ++i) {
            var e = out.elements[i] - out_pred.elements[i];
            result += e * e;
        }
    }
    return result;
}


let mutate = fun(@layer: layer*; error: f32; temp: f32) => void {
        
    var delta_error = error - last_error;
        
    for (var bias_idx = 0; bias_idx < bias.elements.length; ++bias_idx) {
        var delta = delta_bias.elements[bias_idx];
        
        var target_grad = Math::sign(delta * (-delta_error));
        var current_grad = grad_bias.elements[bias_idx];
        var new_grad = Math::lerp(current_grad, target_grad, 0.001);
        grad_bias.elements[bias_idx] = new_grad;
        
        var new_delta = delta*0.9 + Random::rand_f32(0.0, Math::sign(new_grad) * temp);
        bias.elements[bias_idx] += new_delta;
        delta_bias.elements[bias_idx] = new_delta;
    }
    
    for (var weight_idx = 0; weight_idx < weights.elements.length; ++weight_idx) {
        var delta = delta_weights.elements[weight_idx];
        var target_grad = Math::sign(delta * (-delta_error));
        var current_grad = grad_weights.elements[weight_idx];
        var new_grad = Math::lerp(current_grad, target_grad, 0.001);
        grad_weights.elements[weight_idx] = new_grad;
        
        var new_delta = delta*0.9 + Random::rand_f32(0.0, Math::sign(new_grad) * temp);
        weights.elements[weight_idx] += new_delta;
        delta_weights.elements[weight_idx] = new_delta;
    }
    last_error = error;   
}

let mutate = fun(@network: network; error: f32; temp: f32) => void {
    for (var layer_idx = 0; layer_idx < layers.length; ++layer_idx) {
        mutate(&layers[layer_idx], error, temp);
    }
}

var train = fun(network: network; dataset: dataset) => void {
    let temp_start = 0.0001;
    let temp_end = 0.0001;
    
    let max_iter = 100000;
    for (var iter = 0; iter < max_iter; ++iter) {
        var mse = execute(network, dataset);
        var t = (iter@f32 + 1.0) / max_iter@f32;
        var temp = Math::lerp(temp_start, temp_end, t);
        if (iter % 10000 == 0) {
            debug_print("iter", iter);
            debug_print("mse", mse);
            debug_print("temp", temp);
        }
        mutate(network, mse, temp);
    }
}


["compile.entry"]
["compile.libs" : "kernel32.lib, libopenlibm.a"]
["compile.ll"]
["compile.debuginfo" : "true"]
["compile.run"]
["compile.opt" : "4"]
let main = fun () => void {
    test_matrix();
    var net = create_network(2, 2, 1);
    var data = xor_dataset();
    
    train(net, data);
    execute(net, data, true);
}